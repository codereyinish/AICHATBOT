{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8691e61c-d512-414d-bcf3-0ba723e24bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manishbista/anaconda3/envs/transformer_env/lib/python3.8/site-packages/transformers/utils/generic.py:311: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Users/manishbista/anaconda3/envs/transformer_env/lib/python3.8/site-packages/huggingface_hub-0.23.0-py3.8.egg/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "import gradio as gr\n",
    "\n",
    "Chatbot = pipeline(task = \"conversational\", model =\"facebook/blenderbot-400M-distill\")\n",
    " #text, get it from user from gradio\n",
    "\n",
    "message_list = []\n",
    "response_list = []\n",
    "\n",
    "def mini_chatbot(message, history):\n",
    "    conversation = Conversation(text = message, \n",
    "                                past_user_inputs = message_list, \n",
    "                                generated_responses = response_list)\n",
    "    response = Chatbot(conversation)\n",
    "    return response.generated_responses[-1]\n",
    "demo_chatbot = gr.ChatInterface(mini_chatbot, title=\"AI Chatbot\" , description=\"Enter text to CHAT with AI\")\n",
    "demo_chatbot.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bf0af-8ecf-4caa-a928-6c793f8eaa98",
   "metadata": {},
   "source": [
    "#so everytime we call this function, a new instance of Conversation object is created, a --init fucntion is implemented updating user_inputs and generated_responses value (which is done through sub fucntion inside --init function, --init fucntion in Python is sth that gets automatically implemented everytime an object is instatnatiated, ok record of conversation is stored inside the Conversation class with above process, BUT how message_list and response_list will get automatically updated, (since we have to use fresh updated message_list and response_list, ) , it is done automatically. Because we \"past_user_inputs = message_list \" means past_user_input is also Referencing or pointing to same location as the message_list so appending value insdie past list also udpated message_lsit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b24c21-776e-4769-9349-7cd455bc2b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
